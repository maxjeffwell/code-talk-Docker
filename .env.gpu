# GPU Deployment Configuration (Triton/TensorRT)
# Usage: cp .env.gpu .env && docker compose -f docker-compose.yml -f docker-compose.triton.yml up

NODE_ENV=production

# Database
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/code_talk_db

# Authentication
JWT_SECRET=your_jwt_secret_change_in_production

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=redis_password

# CORS
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:80

# AI Backend - Triton via adapter (GPU accelerated)
INFERENCE_URL=http://triton-adapter:8001
AI_GATEWAY_URL=http://shared-ai-gateway:8002

# Triton direct access (for services that support it)
TRITON_HTTP_URL=http://triton:8001
TRITON_GRPC_URL=triton:8002

# GPU Configuration
CUDA_VISIBLE_DEVICES=1

# Deployment type marker
DEPLOYMENT_TYPE=gpu-triton
